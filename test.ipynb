{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "from dataclasses import dataclass\n",
    "from database import SuperBase\n",
    "from models import create_article_meta, ArticleCrud\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class ArxivController:\n",
    "    \"\"\"\n",
    "    # you are going to create a sqlite database named arxiv.db\n",
    "    # you are going to download pdf files into folder ./downloads\n",
    "    ar = ArxivController(database_name=\"arxiv\", \n",
    "        download_path=\"./downloads\")\n",
    "\n",
    "    # search for arxiv papers user query `deep learning`\n",
    "    ar.search_articles(query=\"deep learning\")\n",
    "\n",
    "    # save articles and download pdf files\n",
    "    ar.save_download()\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    database_name:str = 'arxiv'\n",
    "    download_path:str = './downloads'\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.superbase = SuperBase(self.database_name)\n",
    "        self.ArticleMeta = create_article_meta(self.superbase)\n",
    "        self.article_crud = ArticleCrud(self.superbase, self.ArticleMeta)\n",
    "        self.superbase.Base.metadata.create_all(bind=self.superbase.engine)\n",
    "        self.search = None\n",
    "        os.makedirs(self.download_path, exist_ok=True)\n",
    "\n",
    "    def search_articles(self, \n",
    "               query:str,\n",
    "               id_list:list = None, \n",
    "               max_results:int = 10, \n",
    "               sort_by = arxiv.SortCriterion.Relevance,\n",
    "               sort_order = arxiv.SortOrder.Descending):\n",
    "        \n",
    "        search = arxiv.Search(\n",
    "            query=query,\n",
    "            id_list= [] if id_list is None else id_list,\n",
    "            max_results= max_results,\n",
    "            sort_by= sort_by,\n",
    "            sort_order= sort_order\n",
    "        )\n",
    "        self.search = search\n",
    "\n",
    "    def save_download(self):\n",
    "        for result in self.search.results():\n",
    "\n",
    "            print(\"Downloading pdf {}\".format(result.pdf_url))\n",
    "            pdf_path = result.download_pdf(dirpath=self.download_path)\n",
    "            pdf_path = os.path.abspath(pdf_path)\n",
    "\n",
    "            article_meta = self.ArticleMeta(\n",
    "                entry_id=result.entry_id,\n",
    "                updated=result.updated,\n",
    "                published=result.published,\n",
    "                title=result.title,\n",
    "                authors=', '.join([a.name for a in result.authors]),\n",
    "                summary=result.summary,\n",
    "                comment=result.comment,\n",
    "                journal_ref=result.journal_ref,\n",
    "                doi=result.doi,\n",
    "                primary_category=result.primary_category,\n",
    "                categories=', '.join([c for c in result.categories]),\n",
    "                links=', '.join([l.href for l in result.links]),\n",
    "                pdf_url=result.pdf_url,\n",
    "                pdf_path = pdf_path\n",
    "            )\n",
    "            \n",
    "\n",
    "            self.article_crud.create(article_meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./databases\n",
    "!rm -rf ./downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = ArxivController()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar.search_articles(query=\"deep learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pdf http://arxiv.org/pdf/1805.08355v1\n",
      "Downloading pdf http://arxiv.org/pdf/1806.01756v1\n",
      "Downloading pdf http://arxiv.org/pdf/1908.02130v1\n",
      "Downloading pdf http://arxiv.org/pdf/1812.05448v4\n",
      "Downloading pdf http://arxiv.org/pdf/1705.03921v1\n",
      "Downloading pdf http://arxiv.org/pdf/1901.02354v2\n",
      "Downloading pdf http://arxiv.org/pdf/2010.05125v2\n",
      "Downloading pdf http://arxiv.org/pdf/1602.00203v1\n",
      "Downloading pdf http://arxiv.org/pdf/1805.04825v1\n",
      "Downloading pdf http://arxiv.org/pdf/1901.09388v2\n"
     ]
    }
   ],
   "source": [
    "ar.save_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
